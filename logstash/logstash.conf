input {
  jdbc {
    jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
    jdbc_driver_library => "/usr/share/logstash-core/lib/jars/mysql-connector-java.jar"
    jdbc_connection_string => "jdbc:mysql://host.docker.internal:3306/semestralkaB?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true"
    jdbc_user => "root"
    jdbc_password => "root"
    statement => "SELECT measured_value_id, measured_on, measured_value, sensor_id, sensor_name, measuring_device_id, device_name, user_id, username
                  FROM measured_value mv
                  JOIN sensor s ON mv.sensor_sensor_id = s.sensor_id
                  JOIN measuring_device md ON s.measuring_device_measuring_device_id = md.measuring_device_id
                  JOIN user u ON md.user_user_id = u.user_id
                  WHERE measured_value_id > :sql_last_value
                  ORDER BY measured_value_id ASC;"
    use_column_value => true
    #TODO fix bere posledni zaznam duplicitne -> diky presnosti -> logstash pouziva jen na milisekundy :(
    #tracking_column => "measured_on"
    #tracking_column_type => "timestamp"
    #WHERE measured_on > :sql_last_value
    tracking_column => "measured_value_id"
    tracking_column_type => "numeric"
    schedule => "* * * * *"
    last_run_metadata_path => "/logstash_dir/.logstash_jdbc_last_run"
    jdbc_default_timezone => "UTC"
  }

  tcp {
    port => 5000
    codec => json
  }
}

filter {
  # Můžeš přidat další filtry, např. parsování logů, přidávání tagů, atd.
  mutate {
    remove_field => ["@version", "host"]  # Odebere pole, která nejsou nutná
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    #index => "logs-%{+YYYY.MM.dd}"  # Vytváří nový index denně
    index => "measured_value"
  }

  stdout { codec => rubydebug }  # Volitelně, pro zobrazení logů v konzoli
}